# C4 Level 2: Container Diagram

**Generated:** 2026-01-15
**System:** Edinburgh Finds

## Purpose

This diagram shows the high-level technical building blocks of Edinburgh Finds, including the web application, data engine, database, and file storage.

## Diagram

```mermaid
graph TB
    %% Users
    User["üë§ End User"]
    Admin["üë§ Data Administrator"]

    %% System Boundary
    subgraph System["Edinburgh Finds Platform"]
        direction TB
        Web["üåê Web Application<br/><b>Tech: Next.js 16, React 19, TypeScript 5</b><br/>Server-side rendered UI that displays<br/>listings and venue data to users"]

        DataEngine["üîß Data Engine<br/><b>Tech: Python, Pydantic, aiohttp</b><br/>Stage 1: Ingests raw data from APIs<br/>Stage 2: Extracts structured listings<br/>Tracks success/failures with validation"]

        DB["üóÑÔ∏è Database<br/><b>Tech: SQLite (via Prisma)</b><br/>Stores listings, categories,<br/>raw ingestions, and extractions"]

        RawStorage["üíæ Raw Data Storage<br/><b>Tech: File System (JSON)</b><br/>Stores raw JSON responses<br/>from external APIs"]
    end

    %% External Systems
    Serper["‚öôÔ∏è Serper API"]
    GooglePlaces["‚öôÔ∏è Google Places API"]
    OSM["‚öôÔ∏è OpenStreetMap API"]
    OpenChargeMap["‚öôÔ∏è Open Charge Map API"]
    SportScotland["‚öôÔ∏è Sport Scotland API"]
    EdinburghCouncil["‚öôÔ∏è Edinburgh Council API"]

    %% User Relationships
    User -->|"HTTPS"| Web
    Admin -->|"Runs CLI commands"| DataEngine

    %% Internal Relationships
    Web -->|"SQL queries via Prisma"| DB
    DataEngine -->|"Writes raw data / SQL"| DB
    DataEngine -->|"Saves JSON files"| RawStorage
    DataEngine -->|"Reads for processing"| RawStorage

    %% External API Relationships
    DataEngine -->|"Fetches search results / HTTPS"| Serper
    DataEngine -->|"Fetches venue data / HTTPS"| GooglePlaces
    DataEngine -->|"Fetches geo data / HTTPS"| OSM
    DataEngine -->|"Fetches charging data / HTTPS"| OpenChargeMap
    DataEngine -->|"Fetches sports data / HTTPS"| SportScotland
    DataEngine -->|"Fetches council data / HTTPS"| EdinburghCouncil
```

## Containers

| Container | Technology | Responsibility |
|-----------|-----------|----------------|
| Web Application | Next.js 16, React 19, TypeScript 5, Prisma Client 5, Tailwind CSS 4 | Delivers server-side rendered UI, fetches listings from database, displays venue data to end users |
| Data Engine | Python, Pydantic, PyYAML, aiohttp, Prisma (Python) | **Stage 1 (Ingestion):** Runs data connectors, fetches from external APIs, stores raw JSON with deduplication. **Stage 2 (Extraction):** Transforms raw data to schema, validates with Pydantic, tracks extraction success/failures |
| Database | SQLite via Prisma ORM | Stores validated listings, categories, raw ingestions (RawIngestion), extracted listings (ExtractedListing), failed extractions (FailedExtraction), and listing relationships (ListingRelationship) |
| Raw Data Storage | File System (JSON files in `engine/data/raw/`) | Persists raw JSON responses from external APIs for auditing, reprocessing, and debugging |

## Data Flow

### Stage 1: Ingestion (Raw Data Capture)
1. **Trigger Ingestion**: Data administrators run CLI commands (`python -m engine.ingestion.run_<source>`)
2. **Fetch from APIs**: Data Engine connectors fetch data from external APIs (Serper, Google Places, OSM, OpenChargeMap, Edinburgh Council, Sport Scotland)
3. **Deduplication Check**: Compute SHA-256 hash; skip if already ingested
4. **Raw Storage**: Raw JSON responses saved to `engine/data/raw/<source>/<timestamp>_<id>.json`
5. **Track Ingestion**: Create `RawIngestion` record in database with file path, hash, source metadata

### Stage 2: Extraction (Structured Processing)
6. **Trigger Extraction**: CLI commands process `RawIngestion` records
7. **Transform & Validate**: Parse raw JSON, split into `attributes` and `discovered_attributes`, validate with Pydantic
8. **Track Extraction**: Create `ExtractedListing` (success) or `FailedExtraction` (failure with retry tracking)
9. **Upsert Listings**: Validated `ExtractedListing` data upserted into `Listing` table with trust rules applied

### User Access
10. **Web Display**: End users access the web application, which queries validated `Listing` records and renders venue pages

## Technology Stack Summary

- **Frontend:** Next.js 16, React 19, TypeScript 5, Tailwind CSS 4
- **Backend:** Python with Pydantic, aiohttp for async HTTP requests
- **Database:** SQLite with Prisma ORM (TypeScript and Python clients)
- **Storage:** Local file system for raw JSON data
- **Infrastructure:** CLI-based data pipeline, server-side rendering

## Key Architectural Patterns

- **Separation of Concerns**: Web application (read-only) is decoupled from data engine (write-heavy)
- **Two-Stage Pipeline**: Ingestion (raw capture) separated from extraction (structured processing) for data lineage and reprocessing
- **Raw Data Preservation**: All external API responses stored as raw JSON for auditing, reprocessing, and debugging
- **Extraction Tracking**: Success (`ExtractedListing`) and failure (`FailedExtraction`) tracked separately with retry logic
- **Schema Validation**: Pydantic models validate all data before database insertion
- **Dual-Bucket Attributes**: Structured `attributes` (validated) vs `discovered_attributes` (flexible AI-extracted)
- **Deduplication**: Content hashing (SHA-256) prevents duplicate ingestions and extractions
